{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, inspect, re\n",
    "sys.path.append(\"/home/vbhargava/feature_test0/msaction_backend/common/BU3.0_core/util/Py_utils/taxonomy_utils\")\n",
    "import time, logging\n",
    "numeric_level = getattr(logging, 'INFO', None)\n",
    "stdout_handler = logging.StreamHandler(sys.stdout)\n",
    "logging.basicConfig(level=numeric_level,\n",
    "                        format='%(asctime)s %(levelname)s %(name)s: %(message)s',\n",
    "                        handlers=[stdout_handler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.s3_ops import S3_OPs\n",
    "from libs.s3_stream import S3Stream\n",
    "from libs.configs import Config\n",
    "from libs.nio_executor import NIO\n",
    "from libs import utils\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = '/home/vbhargava/feature_test0/msaction_backend/customers/raj_ford_test/common/config/inputs/platform_config.xml'\n",
    "lmt_src = 's3://qubole-ford/taxonomy_cs/test1/src/'\n",
    "lmt_data = 's3://qubole-ford/taxonomy_cs/test1/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_data = Config.get_qubole_config(config)\n",
    "ACCESS_KEY=config_data['access_key']\n",
    "SECRET_KEY=config_data['secret_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TG_EXTRACT_REGEX = '^.*?/([a-zA-Z]+\\-?[0-9]*)/$' \n",
    "FILE_EXTRACT_REGEX = '^.*/([a-zA-Z0-9.\\-_]{0,255}.csv)$' #'^.*/([a-zA-Z0-9.\\-_]{0,255}.csv)$'\n",
    "TARGET_EXTRACT_REGEX ='^.*,?(target_[A-Za-z0-9_-]+).*$'\n",
    "VALID_FILE_KEY_REGEX = '^(.*/([a-zA-Z]+\\-?[0-9]*)?/)?(([a-zA-Z]+\\-?[0-9]*?)_([0-9]{4}-[0-9]{2}-[0-9]{2}?)_([a-zA-Z0-9.\\-_]+?).csv?)$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_ops = S3_OPs(ACCESS_KEY, SECRET_KEY)\n",
    "\n",
    "def filename_by_key(key):\n",
    "    return get_val_by_regex(key, FILE_EXTRACT_REGEX, error_msg=\"Not vaild key for taxonomy data csv file\")\n",
    "\n",
    "def find_by_data_tg(key, regex):\n",
    "    return get_val_by_regex(key, regex, error_msg=\"Not vaild taxonomy data dir\")\n",
    "\n",
    "        \n",
    "def get_val_by_regex(key, regex, error_msg=\"can't be extract a val.\"):\n",
    "    matched = re.findall(regex, key)\n",
    "    if len(matched) > 0:\n",
    "        return matched[0]\n",
    "    else:\n",
    "        raise Exception(error_msg)\n",
    "        \n",
    "def get_data_n_schema(tg, data_files_loc):\n",
    "    data_file_lock_detail = s3_ops.get_bucket_name(data_files_loc)\n",
    "    files = s3_ops.list_complete(data_file_lock_detail['bucket'], data_file_lock_detail['key'])\n",
    "    res = {}\n",
    "    if len(files)>0:\n",
    "        s3_stream = S3Stream(ACCESS_KEY, SECRET_KEY)\n",
    "        schema = s3_stream.get_header(s3_ops.get_full_s3_path(data_file_lock_detail['bucket'],files[0]['Key']))\n",
    "        #res[tg]={'schema':schema, 'files': files}\n",
    "        res['schema'] = {tg:schema}\n",
    "        res['files'] = {tg:files}\n",
    "    return res\n",
    "\n",
    "def extract_schema(schema):\n",
    "    return schema.replace(\" \",\"\").lower()\n",
    "\n",
    "def validate_schema(schema):\n",
    "    if schema=='': \n",
    "        return {'IsValid' : False, 'schema': schema, 'message' : \"Schema shouldn't be empty\"}\n",
    "    tokens = schema.split(',')\n",
    "    if len(tokens) < 2:\n",
    "         return {'IsValid' : False, 'schema': schema, 'message' : \"Schema should have at least 2 columns\"}\n",
    "    KEY_REGEX = '^[Kk]ey_[A-Za-z0-9_]{2,30}$'\n",
    "    TARGET_REGEX = '^[Tt]arget_[A-Za-z0-9_]{2,30}$'\n",
    "    key_cnt = 0\n",
    "    target_cnt = 0\n",
    "    invalid_headers = []\n",
    "    columns = defaultdict(list)\n",
    "    res = {}\n",
    "    target_col = None\n",
    "    key_cols_set = set()\n",
    "    for t in tokens:\n",
    "        t = t.strip()\n",
    "        if re.match(TARGET_REGEX, t):\n",
    "            target_cnt = target_cnt + 1\n",
    "            target_col = t\n",
    "        elif re.match(KEY_REGEX, t):\n",
    "            key_cnt = key_cnt + 1\n",
    "            key_cols_set.add(t)\n",
    "        else:\n",
    "            invalid_headers.append(t)\n",
    "        columns[t.lower()].append(1)\n",
    "\n",
    "    error_msgs=[]\n",
    "    if target_cnt != 1 :\n",
    "        error_msgs.append(\"Exact one Target column is required!\")\n",
    "    if key_cnt < 1 :\n",
    "        error_msgs.append(\"At least one Key column is required!\")\n",
    "    if len(invalid_headers) > 0 :\n",
    "        error_msgs.append(\"All given columns should Key or Target!\")\n",
    "    for k, v in columns.items():\n",
    "\n",
    "        if len(v) > 1:\n",
    "            print(\"--\")\n",
    "            error_msgs.append(\"Same name: {} should not represent more than one column in schema! cols names are case insensitive. \".format(k))\n",
    "\n",
    "    if len(error_msgs) > 0:\n",
    "        return {'IsValid' : False, 'schema': schema, 'errors' : \" \\n\".join(error_msgs)}\n",
    "    #print(str(key_cnt)+\":\"+str(target_cnt)+\":\"+str(invalid_headers)+\":\"+str(columns))\n",
    "    return {'IsValid' : True, 'Schema': schema.replace(\" \",\"\").lower(), \n",
    "            'TargetCol' : target_col, 'KeyColsSet' : key_cols_set}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_detail(lmt_src, lmt_data, access_key, secret_key):\n",
    "#     Valid data Taxonomy Grps\n",
    "    \n",
    "    #\n",
    "    lmt_data_loc_detail = s3_ops.get_bucket_name(lmt_data)\n",
    "    lmt_data_loc_bucket = lmt_data_loc_detail['bucket']\n",
    "    lmt_data_loc_key = lmt_data_loc_detail['key']\n",
    "    valid_tg_list_res = s3_ops.list_subdirs(lmt_data_loc_detail['bucket'],lmt_data_loc_detail['key'],)\n",
    "    \n",
    "    valid_tgrp_loc_list = [ [find_by_data_tg(item['Prefix'], TG_EXTRACT_REGEX), \n",
    "                         '{}{}'.format(lmt_data, find_by_data_tg(item['Prefix'], TG_EXTRACT_REGEX))] \n",
    "                       for item in valid_tg_list_res]\n",
    "    \n",
    "    collected = NIO.decorated_run_io(task=get_data_n_schema, task_n_args_list=valid_tgrp_loc_list, max_workers=25,)\n",
    "#     return collected\n",
    "    tg_data_schema_dict = {k:extract_schema(v)  for item in collected for k, v in item['result']['schema'].items()}\n",
    "    tg_data_files_dict = {k:{filename_by_key(u['Key']):u for u in v } for item in collected for k, v in item['result']['files'].items()}\n",
    "    target_data_tg_dict = {re.findall(TARGET_EXTRACT_REGEX,V)[0]: K for K, V in tg_data_schema_dict.items()}\n",
    "    \n",
    "    return tg_data_schema_dict, tg_data_files_dict,target_data_tg_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_file(key:str='', regex = VALID_FILE_KEY_REGEX):\n",
    "    if re.match(regex, key) is None:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def extract_info(key:str='', regex = VALID_FILE_KEY_REGEX):\n",
    "    matched = re.findall(regex, key)\n",
    "    return {\n",
    "            'KeyDirPath' : matched[0][0],\n",
    "            'ParentDir' : matched[0][1],\n",
    "            'FileName' : matched[0][2],\n",
    "            'FileGrp' :  matched[0][3],\n",
    "            'Date' :  matched[0][4],\n",
    "            'ClientName' : matched[0][5]\n",
    "           }\n",
    "def extract_info_with_bucket(key:str='', bucket = ''):\n",
    "    res = extract_info(key)\n",
    "    res.update({'Bucket' : bucket})\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouped_tg(collected, tg_files_dict_type='new_tg_files_dict'):\n",
    "    collect = defaultdict(dict)\n",
    "    tg_f_gen = (item['result'][tg_files_dict_type] for item in collected if len(item['result'][tg_files_dict_type]) > 0)\n",
    "    tg_f_gen2 = (collect[tg].update({filename: file_dict})  for item in tg_f_gen for tg, file_detail_dict in item.items() for filename, file_dict in file_detail_dict.items())\n",
    "    [ i for i in tg_f_gen2]\n",
    "    tg = dict(collect)\n",
    "    return tg\n",
    "\n",
    "def grouped_flag_dict(collected, flag_dict_type='schema_tg_dict'):\n",
    "    f_gen = (item['result'][flag_dict_type] for item in collected if len(item['result'][flag_dict_type]) > 0)\n",
    "    collect = defaultdict(set)\n",
    "    f_gen2 = (collect[K].add(V)  for item in f_gen for K, V in item.items())\n",
    "    [ i for i in f_gen2]\n",
    "    res = dict(collect)\n",
    "    return res\n",
    "\n",
    "def grouped_set_of_flags_dict(collected, flag_dict_type='schema_tg_dict'):\n",
    "    f_gen = (item['result'][flag_dict_type] for item in collected if len(item['result'][flag_dict_type]) > 0)\n",
    "    collect = defaultdict(set)\n",
    "    f_gen2 = (collect[K].update(V)  for item in f_gen for K, V in item.items())\n",
    "    [ i for i in f_gen2]\n",
    "    res = dict(collect)\n",
    "    return res\n",
    "\n",
    "def grouped_set_of_flags(collected, flag_dict_type='invalid_schema_files'):\n",
    "    res_set=set()\n",
    "    f_gen = (res_set.update(item['result'][flag_dict_type]) for item in collected if len(item['result'][flag_dict_type]) > 0)\n",
    "    [ i for i in f_gen]\n",
    "    return res_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def file_process_task(src_file_details):\n",
    "    \n",
    "    invalid_schema_files = set()\n",
    "\n",
    "    target_already_exist_files = set()\n",
    "    \n",
    "    ''' {'key_evt_advertiser_key,target_evt_advertiser_name': {'tg1', 'tg2', ...}}'''\n",
    "    schema_tg_dict = {}\n",
    "    \n",
    "    ''' {'target_evt_advertiser_name': {'tg1', 'tg2', ...}}'''\n",
    "    target_tg_dict = {}\n",
    "\n",
    "    ''' {'tg': {'key_evt_advertiser_key,target_evt_advertiser_name', '',...}}'''\n",
    "    new_tg_schema_dict = {}\n",
    "    ''' {'tg': {'AdvertiserReporting_2020-06-01_ford.csv': {file detailed obj dict} }  }'''\n",
    "    new_tg_files_dict = {}\n",
    "    ''' {'tg': {'AdvertiserReporting_2020-06-01_ford.csv': {file detailed obj dict} }  }'''\n",
    "    existing_tg_files_dict = {}\n",
    "\n",
    "\n",
    "    # tg_data_schema_dict = \n",
    "    # tg_data_files_dict = \n",
    "    # target_data_tg_dict = \n",
    "\n",
    "#     src_file_details = valid_file_arg[0]\n",
    "    src_file_loc = s3_ops.get_full_s3_path(src_file_details['Bucket'], src_file_details['Key'])\n",
    "\n",
    "    s3_stream = S3Stream(ACCESS_KEY, SECRET_KEY)\n",
    "    schema =  s3_stream.get_header(src_file_loc)\n",
    "    #schema = 'key_evt_advertiser_key, targe_evt_advertiser_name'\n",
    "    validate_res = validate_schema(schema)\n",
    "    if validate_res['IsValid']:\n",
    "        \n",
    "        \n",
    "        \n",
    "        tg = src_file_details['FileGrp']\n",
    "        file_name = src_file_details['FileName']\n",
    "        \n",
    "        if tg_data_schema_dict.get(tg) is None or tg_data_schema_dict.get(tg) != validate_res['Schema']:\n",
    "                \n",
    "#             data_tg_for_target = target_data_tg_dict.get(validate_res['TargetCol'])\n",
    "#             if  data_tg_for_target is not None:# and data_tg_for_target != tg:\n",
    "#                 target_already_exist_files.add((src_file_loc, data_tg_for_target))\n",
    "#             else:\n",
    "            new_tg_schema_dict[tg] = validate_res['Schema']\n",
    "            new_tg_files_dict[tg] = {file_name: src_file_details}\n",
    "        else:\n",
    "            existing_tg_files_dict[tg] = {file_name: src_file_details}\n",
    "        \n",
    "        src_file_details['Schema'] = validate_res['Schema']\n",
    "        schema_tg_dict[validate_res['Schema']] = tg\n",
    "        target_tg_dict[validate_res['TargetCol']] = tg\n",
    "\n",
    "    else:\n",
    "        invalid_schema_files.add((src_file_loc, schema, validate_res['errors']))\n",
    "\n",
    "    return {'invalid_schema_files': invalid_schema_files,\n",
    "#             'target_already_exist_files':target_already_exist_files,\n",
    "            'schema_tg_dict': schema_tg_dict,\n",
    "            'target_tg_dict':target_tg_dict,\n",
    "            'new_tg_schema_dict': new_tg_schema_dict,\n",
    "            'new_tg_files_dict' : new_tg_files_dict,\n",
    "            'existing_tg_files_dict' : existing_tg_files_dict\n",
    "           }\n",
    "\n",
    "\n",
    "\n",
    "def src_list_page_process_task(list_page):\n",
    "    \n",
    "    lmt_src_loc_detail = s3_ops.get_bucket_name(lmt_src)\n",
    "    lmt_src_loc_bucket = lmt_src_loc_detail['bucket']\n",
    "    lmt_src_loc_key = lmt_src_loc_detail['key']\n",
    "    \n",
    "    invalid_files_set = { s3_ops.get_full_s3_path(lmt_src_loc_detail['bucket'], item['Key']) for item in list_page if  not is_valid_file(key=item['Key'])}\n",
    "    valid_file_set = [[utils.dict_append(extract_info_with_bucket(item['Key'], lmt_src_loc_detail['bucket']),item)] for item in list_page if  is_valid_file(key=item['Key']) ]\n",
    "    collected = NIO.decorated_run_io(task=file_process_task, task_n_args_list=valid_file_set, max_workers=25,)\n",
    "#     return collected\n",
    "    return {'invalid_files_set' : invalid_files_set,\n",
    "            'invalid_schema_files': grouped_set_of_flags(collected, flag_dict_type='invalid_schema_files'),\n",
    "#             'target_already_exist_files' : grouped_set_of_flags(collected, flag_dict_type='target_already_exist_files'),\n",
    "            'schema_tg_dict': grouped_flag_dict(collected, flag_dict_type='schema_tg_dict'),\n",
    "            'target_tg_dict': grouped_flag_dict(collected, flag_dict_type='target_tg_dict'),\n",
    "            'new_tg_schema_dict': grouped_flag_dict(collected, flag_dict_type='new_tg_schema_dict'),\n",
    "            'new_tg_files_dict' : grouped_tg(collected, 'new_tg_files_dict'),\n",
    "            'existing_tg_files_dict' : grouped_tg(collected, 'existing_tg_files_dict')\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_src_detail(maxKeysPerReq=3):\n",
    "    lmt_src_loc_detail = s3_ops.get_bucket_name(lmt_src)\n",
    "    lmt_src_loc_bucket = lmt_src_loc_detail['bucket']\n",
    "    lmt_src_loc_key = lmt_src_loc_detail['key']\n",
    "    page_generator = s3_ops.list_gen(lmt_src_loc_bucket, lmt_src_loc_key, maxKeysPerReq=maxKeysPerReq, )\n",
    "    page_args_generator = ([page] for page in page_generator)\n",
    "    #list_page = [i for i in page_generator][0]\n",
    "    collected = NIO.decorated_run_with_args_generator(task=src_list_page_process_task, args_generator=page_args_generator, is_kernal_thread=True,)\n",
    "    \n",
    "    return {'invalid_files_set' : grouped_set_of_flags(collected, flag_dict_type='invalid_files_set'),\n",
    "            'invalid_schema_files': grouped_set_of_flags(collected, flag_dict_type='invalid_schema_files'),\n",
    "#             'target_already_exist_files' : grouped_set_of_flags(collected, flag_dict_type='target_already_exist_files'),\n",
    "            'schema_tg_dict': grouped_set_of_flags_dict(collected, flag_dict_type='schema_tg_dict'),\n",
    "            'target_tg_dict': grouped_set_of_flags_dict(collected, flag_dict_type='target_tg_dict'),\n",
    "            'new_tg_schema_dict': grouped_set_of_flags_dict(collected, flag_dict_type='new_tg_schema_dict'),\n",
    "            'new_tg_files_dict' : grouped_tg(collected, 'new_tg_files_dict'),\n",
    "            'existing_tg_files_dict' : grouped_tg(collected, 'existing_tg_files_dict')\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' E.g. '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def s3_copy_into_data_loc_task(tg, file_name, src_file, src_size, dry_run=True):\n",
    "#     data_file_loc_detail = s3_ops.get_bucket_name(lmt_data)\n",
    "    src_file_loc_detail = s3_ops.get_bucket_name(lmt_src)\n",
    "    src_s3 = 's3://{}/{}'.format(src_file_loc_detail['bucket'], src_file)\n",
    "    dest_s3 = '{}{}/{}'.format(lmt_data,tg, file_name)\n",
    "    if dry_run:\n",
    "        print(\"[dry_run]: S3 copy from {} to {}\".format(src_s3, dest_s3))\n",
    "    else:\n",
    "        pass\n",
    "        #s3_ops.copy(src=src_s3, dest = dest_s3, src_size=src_size)\n",
    "    return 'Copied Successfully! by task'\n",
    "\n",
    "\n",
    "def s3_remove_at_data_loc_task(file,  dry_run=True):\n",
    "    data_file_loc_detail = s3_ops.get_bucket_name(lmt_data)\n",
    "#     src_file_loc_detail = s3_ops.get_bucket_name(lmt_src)\n",
    "#     src_s3 = 's3://{}/{}'.format(lmt_src, src_file)\n",
    "    \n",
    "    if dry_run:\n",
    "        file_loc = 's3://{}/{}'.format(data_file_loc_detail['bucket'], file)\n",
    "        print(\"[dry_run]: S3 delete from {} \".format(file_loc))\n",
    "    else:\n",
    "        pass\n",
    "        #s3_ops.delete_file(data_file_loc_detail['bucket'], file)\n",
    "    return 'Deleted Successfully! by task'\n",
    "\n",
    "''' E.g. '''\n",
    "# s3_copy_into_data_loc_task('tg5', 'tg5_2020-11-01_ford.csv', 'taxonomy_cs/test1/src/tg5_2020-11-01_ford.csv', 48 )\n",
    "# s3_remove_at_data_loc_task('taxonomy_cs/test1/data/tg2/tg2_2020-11-01_ford.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 20:06:35,751:25496 MainThread run_blocking_tasks: starting\n",
      "\n",
      "2020-10-30 20:06:35,752:25496 MainThread run_blocking_tasks: creating executor tasks\n",
      "\n",
      "2020-10-30 20:06:35,752:25496 ThreadPoolExecutor-0_0 (task-0): passed args :['tg1', 's3://qubole-ford/taxonomy_cs/test1/data/tg1']\n",
      "\n",
      "2020-10-30 20:06:35,753:25496 ThreadPoolExecutor-0_1 (task-1): passed args :['tg2', 's3://qubole-ford/taxonomy_cs/test1/data/tg2']\n",
      "\n",
      "2020-10-30 20:06:35,753:25496 ThreadPoolExecutor-0_2 (task-2): passed args :['tg3', 's3://qubole-ford/taxonomy_cs/test1/data/tg3']\n",
      "\n",
      "2020-10-30 20:06:35,754:25496 ThreadPoolExecutor-0_3 (task-3): passed args :['tg5', 's3://qubole-ford/taxonomy_cs/test1/data/tg5']\n",
      "\n",
      "2020-10-30 20:06:35,755:25496 ThreadPoolExecutor-0_4 (task-4): passed args :['tg6', 's3://qubole-ford/taxonomy_cs/test1/data/tg6']\n",
      "\n",
      "2020-10-30 20:06:35,755:25496 ThreadPoolExecutor-0_0 (task-0): running\n",
      "\n",
      "2020-10-30 20:06:35,755:25496 ThreadPoolExecutor-0_5 (task-5): passed args :['tg7', 's3://qubole-ford/taxonomy_cs/test1/data/tg7']\n",
      "\n",
      "2020-10-30 20:06:35,755:25496 MainThread run_blocking_tasks: waiting for executor tasks\n",
      "\n",
      "2020-10-30 20:06:35,756:25496 ThreadPoolExecutor-0_1 (task-1): running\n",
      "\n",
      "2020-10-30 20:06:35,757:25496 ThreadPoolExecutor-0_2 (task-2): running\n",
      "\n",
      "2020-10-30 20:06:35,757:25496 ThreadPoolExecutor-0_3 (task-3): running\n",
      "\n",
      "2020-10-30 20:06:35,758:25496 ThreadPoolExecutor-0_4 (task-4): running\n",
      "\n",
      "2020-10-30 20:06:35,761:25496 ThreadPoolExecutor-0_5 (task-5): running\n",
      "\n",
      "2020-10-30 20:06:35,861:25496 ThreadPoolExecutor-0_0 (task-0): done\n",
      "\n",
      "2020-10-30 20:06:35,906:25496 ThreadPoolExecutor-0_4 (task-4): done\n",
      "\n",
      "2020-10-30 20:06:35,907:25496 ThreadPoolExecutor-0_1 (task-1): done\n",
      "\n",
      "2020-10-30 20:06:35,912:25496 ThreadPoolExecutor-0_3 (task-3): done\n",
      "\n",
      "2020-10-30 20:06:35,915:25496 ThreadPoolExecutor-0_2 (task-2): done\n",
      "\n",
      "2020-10-30 20:06:35,971:25496 ThreadPoolExecutor-0_5 (task-5): done\n",
      "\n",
      "2020-10-30 20:06:35,973:25496 MainThread run_blocking_tasks: exiting\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' Get Existing State of System'''\n",
    "tg_data = extract_data_detail(lmt_src, lmt_data, ACCESS_KEY, SECRET_KEY)\n",
    "tg_data_schema_dict = tg_data[0]\n",
    "tg_data_files_dict = tg_data[1]\n",
    "target_data_tg_dict = tg_data[2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 20:09:44,659   process-id:25496 run_blocking_tasks: starting\n",
      "\n",
      "2020-10-30 20:09:44,660   process-id:25496 run_blocking_tasks: creating executor tasks\n",
      "\n",
      "2020-10-30 20:09:44,754   process-id:61190   (task-0): passed args :[[{'Key': 'taxonomy_cs/test1/src/tg0_202-11-01_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"535b60451f6d20c2826b045438a50fb9\"', 'Size': 48, 'StorageClass': 'STANDARD'}, {'Key': 'taxonomy_cs/test1/src/tg0_2020-11-02_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"7a5d08cbb4c718d16851d1f2b57ffc50\"', 'Size': 27, 'StorageClass': 'STANDARD'}, {'Key': 'taxonomy_cs/test1/src/tg0_2020-11-03_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 21, 21, 36, tzinfo=tzlocal()), 'ETag': '\"b19c288a2ef5e2ec6739cac3674391a6\"', 'Size': 28, 'StorageClass': 'STANDARD'}]]\n",
      "\n",
      "2020-10-30 20:09:44,757   process-id:61190   (task-0): running\n",
      "\n",
      "2020-10-30 20:09:44,760:61190 MainThread run_blocking_tasks: starting\n",
      "\n",
      "2020-10-30 20:09:44,761:61190 MainThread run_blocking_tasks: creating executor tasks\n",
      "\n",
      "2020-10-30 20:09:44,763:61190 ThreadPoolExecutor-1_0 (task-0): passed args :[{'KeyDirPath': 'taxonomy_cs/test1/src/', 'ParentDir': 'src', 'FileName': 'tg0_2020-11-02_ford.csv', 'FileGrp': 'tg0', 'Date': '2020-11-02', 'ClientName': 'ford', 'Bucket': 'qubole-ford', 'Key': 'taxonomy_cs/test1/src/tg0_2020-11-02_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"7a5d08cbb4c718d16851d1f2b57ffc50\"', 'Size': 27, 'StorageClass': 'STANDARD'}]\n",
      "\n",
      "2020-10-30 20:09:44,763:61190 ThreadPoolExecutor-1_1 (task-1): passed args :[{'KeyDirPath': 'taxonomy_cs/test1/src/', 'ParentDir': 'src', 'FileName': 'tg0_2020-11-03_ford.csv', 'FileGrp': 'tg0', 'Date': '2020-11-03', 'ClientName': 'ford', 'Bucket': 'qubole-ford', 'Key': 'taxonomy_cs/test1/src/tg0_2020-11-03_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 21, 21, 36, tzinfo=tzlocal()), 'ETag': '\"b19c288a2ef5e2ec6739cac3674391a6\"', 'Size': 28, 'StorageClass': 'STANDARD'}]\n",
      "\n",
      "2020-10-30 20:09:44,764:61190 MainThread run_blocking_tasks: waiting for executor tasks\n",
      "\n",
      "2020-10-30 20:09:44,764:61190 ThreadPoolExecutor-1_0 (task-0): running\n",
      "\n",
      "2020-10-30 20:09:44,765:61190 ThreadPoolExecutor-1_1 (task-1): running\n",
      "\n",
      "2020-10-30 20:09:44,776   process-id:61191   (task-1): passed args :[[{'Key': 'taxonomy_cs/test1/src/tg10_2020-11-01_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"1aa284fe1180b5d4d776e26ff8a03358\"', 'Size': 49, 'StorageClass': 'STANDARD'}, {'Key': 'taxonomy_cs/test1/src/tg11_2020-11-01_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"b83eaf4009dc42dd2a744fad592339f9\"', 'Size': 48, 'StorageClass': 'STANDARD'}, {'Key': 'taxonomy_cs/test1/src/tg1_2020-11-01_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"e74387593f23233a61d30b719b79a381\"', 'Size': 48, 'StorageClass': 'STANDARD'}]]\n",
      "\n",
      "2020-10-30 20:09:44,778   process-id:61191   (task-1): running\n",
      "\n",
      "2020-10-30 20:09:44,782:61191 MainThread run_blocking_tasks: starting\n",
      "\n",
      "2020-10-30 20:09:44,783:61191 MainThread run_blocking_tasks: creating executor tasks\n",
      "\n",
      "2020-10-30 20:09:44,785:61191 ThreadPoolExecutor-1_0 (task-0): passed args :[{'KeyDirPath': 'taxonomy_cs/test1/src/', 'ParentDir': 'src', 'FileName': 'tg10_2020-11-01_ford.csv', 'FileGrp': 'tg10', 'Date': '2020-11-01', 'ClientName': 'ford', 'Bucket': 'qubole-ford', 'Key': 'taxonomy_cs/test1/src/tg10_2020-11-01_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"1aa284fe1180b5d4d776e26ff8a03358\"', 'Size': 49, 'StorageClass': 'STANDARD'}]\n",
      "\n",
      "2020-10-30 20:09:44,786:61191 ThreadPoolExecutor-1_1 (task-1): passed args :[{'KeyDirPath': 'taxonomy_cs/test1/src/', 'ParentDir': 'src', 'FileName': 'tg11_2020-11-01_ford.csv', 'FileGrp': 'tg11', 'Date': '2020-11-01', 'ClientName': 'ford', 'Bucket': 'qubole-ford', 'Key': 'taxonomy_cs/test1/src/tg11_2020-11-01_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"b83eaf4009dc42dd2a744fad592339f9\"', 'Size': 48, 'StorageClass': 'STANDARD'}]\n",
      "\n",
      "2020-10-30 20:09:44,786:61191 ThreadPoolExecutor-1_0 (task-0): running\n",
      "\n",
      "2020-10-30 20:09:44,794   process-id:61192   (task-2): passed args :[[{'Key': 'taxonomy_cs/test1/src/tg1_2020-11-02_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"e74387593f23233a61d30b719b79a381\"', 'Size': 48, 'StorageClass': 'STANDARD'}, {'Key': 'taxonomy_cs/test1/src/tg2_2020-11-01_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"dde15e0dffb34575c1aa95f81c8867c0\"', 'Size': 50, 'StorageClass': 'STANDARD'}, {'Key': 'taxonomy_cs/test1/src/tg2_2020-11-02_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"dde15e0dffb34575c1aa95f81c8867c0\"', 'Size': 50, 'StorageClass': 'STANDARD'}]]\n",
      "\n",
      "2020-10-30 20:09:44,797   process-id:61192   (task-2): running\n",
      "\n",
      "2020-10-30 20:09:44,786:61191 ThreadPoolExecutor-1_2 (task-2): passed args :[{'KeyDirPath': 'taxonomy_cs/test1/src/', 'ParentDir': 'src', 'FileName': 'tg1_2020-11-01_ford.csv', 'FileGrp': 'tg1', 'Date': '2020-11-01', 'ClientName': 'ford', 'Bucket': 'qubole-ford', 'Key': 'taxonomy_cs/test1/src/tg1_2020-11-01_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"e74387593f23233a61d30b719b79a381\"', 'Size': 48, 'StorageClass': 'STANDARD'}]\n",
      "\n",
      "2020-10-30 20:09:44,787:61191 MainThread run_blocking_tasks: waiting for executor tasks\n",
      "\n",
      "2020-10-30 20:09:44,801:61192 MainThread run_blocking_tasks: starting\n",
      "\n",
      "2020-10-30 20:09:44,787:61191 ThreadPoolExecutor-1_1 (task-1): running\n",
      "\n",
      "2020-10-30 20:09:44,802:61192 MainThread run_blocking_tasks: creating executor tasks\n",
      "\n",
      "2020-10-30 20:09:44,803:61192 ThreadPoolExecutor-1_0 (task-0): passed args :[{'KeyDirPath': 'taxonomy_cs/test1/src/', 'ParentDir': 'src', 'FileName': 'tg1_2020-11-02_ford.csv', 'FileGrp': 'tg1', 'Date': '2020-11-02', 'ClientName': 'ford', 'Bucket': 'qubole-ford', 'Key': 'taxonomy_cs/test1/src/tg1_2020-11-02_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"e74387593f23233a61d30b719b79a381\"', 'Size': 48, 'StorageClass': 'STANDARD'}]\n",
      "\n",
      "2020-10-30 20:09:44,804:61192 ThreadPoolExecutor-1_1 (task-1): passed args :[{'KeyDirPath': 'taxonomy_cs/test1/src/', 'ParentDir': 'src', 'FileName': 'tg2_2020-11-01_ford.csv', 'FileGrp': 'tg2', 'Date': '2020-11-01', 'ClientName': 'ford', 'Bucket': 'qubole-ford', 'Key': 'taxonomy_cs/test1/src/tg2_2020-11-01_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"dde15e0dffb34575c1aa95f81c8867c0\"', 'Size': 50, 'StorageClass': 'STANDARD'}]\n",
      "\n",
      "2020-10-30 20:09:44,805:61192 ThreadPoolExecutor-1_0 (task-0): running\n",
      "\n",
      "2020-10-30 20:09:44,799:61191 ThreadPoolExecutor-1_2 (task-2): running\n",
      "\n",
      "2020-10-30 20:09:44,814   process-id:61193   (task-3): passed args :[[{'Key': 'taxonomy_cs/test1/src/tg2_2020-11-03_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"dde15e0dffb34575c1aa95f81c8867c0\"', 'Size': 50, 'StorageClass': 'STANDARD'}, {'Key': 'taxonomy_cs/test1/src/tg4_2020-11-01_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"ee6aeaee97c71bc6e4c3cea71ad78e35\"', 'Size': 48, 'StorageClass': 'STANDARD'}, {'Key': 'taxonomy_cs/test1/src/tg4_2020-11-02_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"ee6aeaee97c71bc6e4c3cea71ad78e35\"', 'Size': 48, 'StorageClass': 'STANDARD'}]]\n",
      "\n",
      "2020-10-30 20:09:44,816   process-id:61193   (task-3): running\n",
      "\n",
      "2020-10-30 20:09:44,805:61192 ThreadPoolExecutor-1_2 (task-2): passed args :[{'KeyDirPath': 'taxonomy_cs/test1/src/', 'ParentDir': 'src', 'FileName': 'tg2_2020-11-02_ford.csv', 'FileGrp': 'tg2', 'Date': '2020-11-02', 'ClientName': 'ford', 'Bucket': 'qubole-ford', 'Key': 'taxonomy_cs/test1/src/tg2_2020-11-02_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"dde15e0dffb34575c1aa95f81c8867c0\"', 'Size': 50, 'StorageClass': 'STANDARD'}]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 20:09:44,806:61192 MainThread run_blocking_tasks: waiting for executor tasks\n",
      "\n",
      "2020-10-30 20:09:44,806:61192 ThreadPoolExecutor-1_1 (task-1): running\n",
      "\n",
      "2020-10-30 20:09:44,819:61193 MainThread run_blocking_tasks: starting\n",
      "\n",
      "2020-10-30 20:09:44,821:61193 MainThread run_blocking_tasks: creating executor tasks\n",
      "\n",
      "2020-10-30 20:09:44,822:61193 ThreadPoolExecutor-1_0 (task-0): passed args :[{'KeyDirPath': 'taxonomy_cs/test1/src/', 'ParentDir': 'src', 'FileName': 'tg2_2020-11-03_ford.csv', 'FileGrp': 'tg2', 'Date': '2020-11-03', 'ClientName': 'ford', 'Bucket': 'qubole-ford', 'Key': 'taxonomy_cs/test1/src/tg2_2020-11-03_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"dde15e0dffb34575c1aa95f81c8867c0\"', 'Size': 50, 'StorageClass': 'STANDARD'}]\n",
      "\n",
      "2020-10-30 20:09:44,823:61193 ThreadPoolExecutor-1_1 (task-1): passed args :[{'KeyDirPath': 'taxonomy_cs/test1/src/', 'ParentDir': 'src', 'FileName': 'tg4_2020-11-01_ford.csv', 'FileGrp': 'tg4', 'Date': '2020-11-01', 'ClientName': 'ford', 'Bucket': 'qubole-ford', 'Key': 'taxonomy_cs/test1/src/tg4_2020-11-01_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"ee6aeaee97c71bc6e4c3cea71ad78e35\"', 'Size': 48, 'StorageClass': 'STANDARD'}]\n",
      "\n",
      "2020-10-30 20:09:44,818:61192 ThreadPoolExecutor-1_2 (task-2): running\n",
      "\n",
      "2020-10-30 20:09:44,823:61193 ThreadPoolExecutor-1_2 (task-2): passed args :[{'KeyDirPath': 'taxonomy_cs/test1/src/', 'ParentDir': 'src', 'FileName': 'tg4_2020-11-02_ford.csv', 'FileGrp': 'tg4', 'Date': '2020-11-02', 'ClientName': 'ford', 'Bucket': 'qubole-ford', 'Key': 'taxonomy_cs/test1/src/tg4_2020-11-02_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"ee6aeaee97c71bc6e4c3cea71ad78e35\"', 'Size': 48, 'StorageClass': 'STANDARD'}]\n",
      "\n",
      "2020-10-30 20:09:44,824:61193 MainThread run_blocking_tasks: waiting for executor tasks\n",
      "\n",
      "2020-10-30 20:09:44,824:61193 ThreadPoolExecutor-1_0 (task-0): running\n",
      "\n",
      "2020-10-30 20:09:44,829:61190 ThreadPoolExecutor-1_0 (task-0): done\n",
      "\n",
      "2020-10-30 20:09:44,832:61190 ThreadPoolExecutor-1_1 (task-1): done\n",
      "\n",
      "2020-10-30 20:09:44,832   process-id:61194   (task-4): passed args :[[{'Key': 'taxonomy_cs/test1/src/tg4_2020-11-03_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"ee6aeaee97c71bc6e4c3cea71ad78e35\"', 'Size': 48, 'StorageClass': 'STANDARD'}, {'Key': 'taxonomy_cs/test1/src/tg5_2020-11-01_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"471c56a20b21f692659b2f5c68c0b713\"', 'Size': 48, 'StorageClass': 'STANDARD'}, {'Key': 'taxonomy_cs/test1/src/tg5_2020-11-02_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"471c56a20b21f692659b2f5c68c0b713\"', 'Size': 48, 'StorageClass': 'STANDARD'}]]\n",
      "\n",
      "2020-10-30 20:09:44,825:61193 ThreadPoolExecutor-1_1 (task-1): running\n",
      "\n",
      "2020-10-30 20:09:44,834:61190 MainThread run_blocking_tasks: exiting\n",
      "\n",
      "2020-10-30 20:09:44,835   process-id:61194   (task-4): running\n",
      "\n",
      "2020-10-30 20:09:44,836   process-id:61190   (task-0): done\n",
      "\n",
      "2020-10-30 20:09:44,839:61194 MainThread run_blocking_tasks: starting\n",
      "\n",
      "2020-10-30 20:09:44,840:61194 MainThread run_blocking_tasks: creating executor tasks\n",
      "\n",
      "2020-10-30 20:09:44,841:61194 ThreadPoolExecutor-1_0 (task-0): passed args :[{'KeyDirPath': 'taxonomy_cs/test1/src/', 'ParentDir': 'src', 'FileName': 'tg4_2020-11-03_ford.csv', 'FileGrp': 'tg4', 'Date': '2020-11-03', 'ClientName': 'ford', 'Bucket': 'qubole-ford', 'Key': 'taxonomy_cs/test1/src/tg4_2020-11-03_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"ee6aeaee97c71bc6e4c3cea71ad78e35\"', 'Size': 48, 'StorageClass': 'STANDARD'}]\n",
      "\n",
      "2020-10-30 20:09:44,842:61194 ThreadPoolExecutor-1_1 (task-1): passed args :[{'KeyDirPath': 'taxonomy_cs/test1/src/', 'ParentDir': 'src', 'FileName': 'tg5_2020-11-01_ford.csv', 'FileGrp': 'tg5', 'Date': '2020-11-01', 'ClientName': 'ford', 'Bucket': 'qubole-ford', 'Key': 'taxonomy_cs/test1/src/tg5_2020-11-01_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"471c56a20b21f692659b2f5c68c0b713\"', 'Size': 48, 'StorageClass': 'STANDARD'}]\n",
      "\n",
      "2020-10-30 20:09:44,843:61194 ThreadPoolExecutor-1_2 (task-2): passed args :[{'KeyDirPath': 'taxonomy_cs/test1/src/', 'ParentDir': 'src', 'FileName': 'tg5_2020-11-02_ford.csv', 'FileGrp': 'tg5', 'Date': '2020-11-02', 'ClientName': 'ford', 'Bucket': 'qubole-ford', 'Key': 'taxonomy_cs/test1/src/tg5_2020-11-02_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"471c56a20b21f692659b2f5c68c0b713\"', 'Size': 48, 'StorageClass': 'STANDARD'}]\n",
      "\n",
      "2020-10-30 20:09:44,843:61194 MainThread run_blocking_tasks: waiting for executor tasks\n",
      "\n",
      "2020-10-30 20:09:44,826:61193 ThreadPoolExecutor-1_2 (task-2): running\n",
      "\n",
      "2020-10-30 20:09:44,843:61194 ThreadPoolExecutor-1_0 (task-0): running\n",
      "\n",
      "2020-10-30 20:09:44,848:61191 ThreadPoolExecutor-1_0 (task-0): done\n",
      "\n",
      "2020-10-30 20:09:44,850   process-id:61195   (task-5): passed args :[[{'Key': 'taxonomy_cs/test1/src/tg5_2020-11-03_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"471c56a20b21f692659b2f5c68c0b713\"', 'Size': 48, 'StorageClass': 'STANDARD'}, {'Key': 'taxonomy_cs/test1/src/tg5_2020-11-04_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"f87ad6041aa111ac6b6d0776be1c774f\"', 'Size': 50, 'StorageClass': 'STANDARD'}, {'Key': 'taxonomy_cs/test1/src/tg6_2020-11-01_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"ae64f1e8ed00a66a125cfeee7223cfa2\"', 'Size': 49, 'StorageClass': 'STANDARD'}]]\n",
      "\n",
      "2020-10-30 20:09:44,853   process-id:61195   (task-5): running\n",
      "\n",
      "2020-10-30 20:09:44,856:61195 MainThread run_blocking_tasks: starting\n",
      "\n",
      "2020-10-30 20:09:44,857:61195 MainThread run_blocking_tasks: creating executor tasks\n",
      "\n",
      "2020-10-30 20:09:44,844:61194 ThreadPoolExecutor-1_1 (task-1): running\n",
      "\n",
      "2020-10-30 20:09:44,858:61195 ThreadPoolExecutor-1_0 (task-0): passed args :[{'KeyDirPath': 'taxonomy_cs/test1/src/', 'ParentDir': 'src', 'FileName': 'tg5_2020-11-03_ford.csv', 'FileGrp': 'tg5', 'Date': '2020-11-03', 'ClientName': 'ford', 'Bucket': 'qubole-ford', 'Key': 'taxonomy_cs/test1/src/tg5_2020-11-03_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"471c56a20b21f692659b2f5c68c0b713\"', 'Size': 48, 'StorageClass': 'STANDARD'}]\n",
      "\n",
      "2020-10-30 20:09:44,858:61191 ThreadPoolExecutor-1_1 (task-1): done\n",
      "\n",
      "2020-10-30 20:09:44,859:61195 ThreadPoolExecutor-1_1 (task-1): passed args :[{'KeyDirPath': 'taxonomy_cs/test1/src/', 'ParentDir': 'src', 'FileName': 'tg5_2020-11-04_ford.csv', 'FileGrp': 'tg5', 'Date': '2020-11-04', 'ClientName': 'ford', 'Bucket': 'qubole-ford', 'Key': 'taxonomy_cs/test1/src/tg5_2020-11-04_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"f87ad6041aa111ac6b6d0776be1c774f\"', 'Size': 50, 'StorageClass': 'STANDARD'}]\n",
      "\n",
      "2020-10-30 20:09:44,860:61195 ThreadPoolExecutor-1_2 (task-2): passed args :[{'KeyDirPath': 'taxonomy_cs/test1/src/', 'ParentDir': 'src', 'FileName': 'tg6_2020-11-01_ford.csv', 'FileGrp': 'tg6', 'Date': '2020-11-01', 'ClientName': 'ford', 'Bucket': 'qubole-ford', 'Key': 'taxonomy_cs/test1/src/tg6_2020-11-01_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"ae64f1e8ed00a66a125cfeee7223cfa2\"', 'Size': 49, 'StorageClass': 'STANDARD'}]\n",
      "\n",
      "2020-10-30 20:09:44,860:61195 ThreadPoolExecutor-1_0 (task-0): running\n",
      "\n",
      "2020-10-30 20:09:44,862:61191 ThreadPoolExecutor-1_2 (task-2): done\n",
      "\n",
      "2020-10-30 20:09:44,864:61191 MainThread run_blocking_tasks: exiting\n",
      "\n",
      "2020-10-30 20:09:44,845:61194 ThreadPoolExecutor-1_2 (task-2): running\n",
      "\n",
      "2020-10-30 20:09:44,865:61192 ThreadPoolExecutor-1_0 (task-0): done\n",
      "\n",
      "2020-10-30 20:09:44,866   process-id:61191   (task-1): done\n",
      "\n",
      "2020-10-30 20:09:44,860:61195 MainThread run_blocking_tasks: waiting for executor tasks\n",
      "\n",
      "2020-10-30 20:09:44,873:61192 ThreadPoolExecutor-1_1 (task-1): done\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 20:09:44,861:61195 ThreadPoolExecutor-1_1 (task-1): running\n",
      "\n",
      "2020-10-30 20:09:44,877:61192 ThreadPoolExecutor-1_2 (task-2): done\n",
      "\n",
      "2020-10-30 20:09:44,879:61192 MainThread run_blocking_tasks: exiting\n",
      "\n",
      "2020-10-30 20:09:44,880   process-id:61192   (task-2): done\n",
      "\n",
      "2020-10-30 20:09:44,863:61195 ThreadPoolExecutor-1_2 (task-2): running\n",
      "\n",
      "2020-10-30 20:09:44,881:61193 ThreadPoolExecutor-1_0 (task-0): done\n",
      "\n",
      "2020-10-30 20:09:44,885:61193 ThreadPoolExecutor-1_2 (task-2): done\n",
      "\n",
      "2020-10-30 20:09:44,887:61193 ThreadPoolExecutor-1_1 (task-1): done\n",
      "\n",
      "2020-10-30 20:09:44,890:61193 MainThread run_blocking_tasks: exiting\n",
      "\n",
      "2020-10-30 20:09:44,891   process-id:61193   (task-3): done\n",
      "\n",
      "2020-10-30 20:09:44,904:61194 ThreadPoolExecutor-1_0 (task-0): done\n",
      "\n",
      "2020-10-30 20:09:44,913:61194 ThreadPoolExecutor-1_2 (task-2): done\n",
      "\n",
      "2020-10-30 20:09:44,915:61194 ThreadPoolExecutor-1_1 (task-1): done\n",
      "\n",
      "2020-10-30 20:09:44,917:61194 MainThread run_blocking_tasks: exiting\n",
      "\n",
      "2020-10-30 20:09:44,916   process-id:61196   (task-6): passed args :[[{'Key': 'taxonomy_cs/test1/src/tg6_2020-11-02_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"ae64f1e8ed00a66a125cfeee7223cfa2\"', 'Size': 49, 'StorageClass': 'STANDARD'}, {'Key': 'taxonomy_cs/test1/src/tg7_2020-11-01_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"653eec710cdbf86149efb89f21912022\"', 'Size': 48, 'StorageClass': 'STANDARD'}, {'Key': 'taxonomy_cs/test1/src/tg7_2020-11-02_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"653eec710cdbf86149efb89f21912022\"', 'Size': 48, 'StorageClass': 'STANDARD'}]]\n",
      "\n",
      "2020-10-30 20:09:44,918   process-id:61194   (task-4): done\n",
      "\n",
      "2020-10-30 20:09:44,918   process-id:61196   (task-6): running\n",
      "\n",
      "2020-10-30 20:09:44,921:61196 MainThread run_blocking_tasks: starting\n",
      "\n",
      "2020-10-30 20:09:44,922:61196 MainThread run_blocking_tasks: creating executor tasks\n",
      "\n",
      "2020-10-30 20:09:44,923:61196 ThreadPoolExecutor-1_0 (task-0): passed args :[{'KeyDirPath': 'taxonomy_cs/test1/src/', 'ParentDir': 'src', 'FileName': 'tg6_2020-11-02_ford.csv', 'FileGrp': 'tg6', 'Date': '2020-11-02', 'ClientName': 'ford', 'Bucket': 'qubole-ford', 'Key': 'taxonomy_cs/test1/src/tg6_2020-11-02_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"ae64f1e8ed00a66a125cfeee7223cfa2\"', 'Size': 49, 'StorageClass': 'STANDARD'}]\n",
      "\n",
      "2020-10-30 20:09:44,924:61196 ThreadPoolExecutor-1_1 (task-1): passed args :[{'KeyDirPath': 'taxonomy_cs/test1/src/', 'ParentDir': 'src', 'FileName': 'tg7_2020-11-01_ford.csv', 'FileGrp': 'tg7', 'Date': '2020-11-01', 'ClientName': 'ford', 'Bucket': 'qubole-ford', 'Key': 'taxonomy_cs/test1/src/tg7_2020-11-01_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"653eec710cdbf86149efb89f21912022\"', 'Size': 48, 'StorageClass': 'STANDARD'}]\n",
      "\n",
      "2020-10-30 20:09:44,925:61196 ThreadPoolExecutor-1_2 (task-2): passed args :[{'KeyDirPath': 'taxonomy_cs/test1/src/', 'ParentDir': 'src', 'FileName': 'tg7_2020-11-02_ford.csv', 'FileGrp': 'tg7', 'Date': '2020-11-02', 'ClientName': 'ford', 'Bucket': 'qubole-ford', 'Key': 'taxonomy_cs/test1/src/tg7_2020-11-02_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"653eec710cdbf86149efb89f21912022\"', 'Size': 48, 'StorageClass': 'STANDARD'}]\n",
      "\n",
      "2020-10-30 20:09:44,925:61196 ThreadPoolExecutor-1_0 (task-0): running\n",
      "\n",
      "2020-10-30 20:09:44,927:61195 ThreadPoolExecutor-1_2 (task-2): done\n",
      "\n",
      "2020-10-30 20:09:44,931:61195 ThreadPoolExecutor-1_0 (task-0): done\n",
      "\n",
      "2020-10-30 20:09:44,932   process-id:25496 run_blocking_tasks: waiting for executor tasks\n",
      "\n",
      "2020-10-30 20:09:44,934:61195 ThreadPoolExecutor-1_1 (task-1): done\n",
      "\n",
      "2020-10-30 20:09:44,935:61195 MainThread run_blocking_tasks: exiting\n",
      "\n",
      "2020-10-30 20:09:44,934   process-id:61197   (task-7): passed args :[[{'Key': 'taxonomy_cs/test1/src/tg7_2020-11-03_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"d54b283d90621ca6b19c85f4c96d4b8f\"', 'Size': 49, 'StorageClass': 'STANDARD'}, {'Key': 'taxonomy_cs/test1/src/tg8_2020-11-01_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"8d575874cb97b2d601ae8542aaf11431\"', 'Size': 48, 'StorageClass': 'STANDARD'}, {'Key': 'taxonomy_cs/test1/src/tg9_2020-11-01_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"b83eaf4009dc42dd2a744fad592339f9\"', 'Size': 48, 'StorageClass': 'STANDARD'}]]\n",
      "\n",
      "2020-10-30 20:09:44,936   process-id:61197   (task-7): running\n",
      "\n",
      "2020-10-30 20:09:44,936   process-id:61195   (task-5): done\n",
      "\n",
      "2020-10-30 20:09:44,925:61196 MainThread run_blocking_tasks: waiting for executor tasks\n",
      "\n",
      "2020-10-30 20:09:44,939:61197 MainThread run_blocking_tasks: starting\n",
      "\n",
      "2020-10-30 20:09:44,926:61196 ThreadPoolExecutor-1_1 (task-1): running\n",
      "\n",
      "2020-10-30 20:09:44,940:61197 MainThread run_blocking_tasks: creating executor tasks\n",
      "\n",
      "2020-10-30 20:09:44,941:61197 ThreadPoolExecutor-1_0 (task-0): passed args :[{'KeyDirPath': 'taxonomy_cs/test1/src/', 'ParentDir': 'src', 'FileName': 'tg7_2020-11-03_ford.csv', 'FileGrp': 'tg7', 'Date': '2020-11-03', 'ClientName': 'ford', 'Bucket': 'qubole-ford', 'Key': 'taxonomy_cs/test1/src/tg7_2020-11-03_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"d54b283d90621ca6b19c85f4c96d4b8f\"', 'Size': 49, 'StorageClass': 'STANDARD'}]\n",
      "\n",
      "2020-10-30 20:09:44,942:61197 ThreadPoolExecutor-1_1 (task-1): passed args :[{'KeyDirPath': 'taxonomy_cs/test1/src/', 'ParentDir': 'src', 'FileName': 'tg8_2020-11-01_ford.csv', 'FileGrp': 'tg8', 'Date': '2020-11-01', 'ClientName': 'ford', 'Bucket': 'qubole-ford', 'Key': 'taxonomy_cs/test1/src/tg8_2020-11-01_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"8d575874cb97b2d601ae8542aaf11431\"', 'Size': 48, 'StorageClass': 'STANDARD'}]\n",
      "\n",
      "2020-10-30 20:09:44,943:61197 ThreadPoolExecutor-1_2 (task-2): passed args :[{'KeyDirPath': 'taxonomy_cs/test1/src/', 'ParentDir': 'src', 'FileName': 'tg9_2020-11-01_ford.csv', 'FileGrp': 'tg9', 'Date': '2020-11-01', 'ClientName': 'ford', 'Bucket': 'qubole-ford', 'Key': 'taxonomy_cs/test1/src/tg9_2020-11-01_ford.csv', 'LastModified': datetime.datetime(2020, 10, 29, 19, 53, 45, tzinfo=tzlocal()), 'ETag': '\"b83eaf4009dc42dd2a744fad592339f9\"', 'Size': 48, 'StorageClass': 'STANDARD'}]\n",
      "\n",
      "2020-10-30 20:09:44,943:61197 MainThread run_blocking_tasks: waiting for executor tasks\n",
      "\n",
      "2020-10-30 20:09:44,943:61197 ThreadPoolExecutor-1_0 (task-0): running\n",
      "\n",
      "2020-10-30 20:09:44,927:61196 ThreadPoolExecutor-1_2 (task-2): running\n",
      "\n",
      "2020-10-30 20:09:44,944:61197 ThreadPoolExecutor-1_1 (task-1): running\n",
      "\n",
      "2020-10-30 20:09:44,945:61197 ThreadPoolExecutor-1_2 (task-2): running\n",
      "\n",
      "2020-10-30 20:09:44,981:61196 ThreadPoolExecutor-1_0 (task-0): done\n",
      "\n",
      "2020-10-30 20:09:44,996:61197 ThreadPoolExecutor-1_0 (task-0): done\n",
      "\n",
      "2020-10-30 20:09:44,998:61196 ThreadPoolExecutor-1_2 (task-2): done\n",
      "\n",
      "2020-10-30 20:09:44,999:61196 ThreadPoolExecutor-1_1 (task-1): done\n",
      "\n",
      "2020-10-30 20:09:45,001:61196 MainThread run_blocking_tasks: exiting\n",
      "\n",
      "2020-10-30 20:09:45,002   process-id:61196   (task-6): done\n",
      "\n",
      "2020-10-30 20:09:45,002:61197 ThreadPoolExecutor-1_2 (task-2): done\n",
      "\n",
      "2020-10-30 20:09:45,011:61197 ThreadPoolExecutor-1_1 (task-1): done\n",
      "\n",
      "2020-10-30 20:09:45,012:61197 MainThread run_blocking_tasks: exiting\n",
      "\n",
      "2020-10-30 20:09:45,013   process-id:61197   (task-7): done\n",
      "\n",
      "2020-10-30 20:09:45,015   process-id:25496 run_blocking_tasks: exiting\n",
      "\n"
     ]
    }
   ],
   "source": [
    "src_delta = extract_src_detail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 22:40:41,747:25496 MainThread run_blocking_tasks: starting\n",
      "\n",
      "2020-10-30 22:40:41,748:25496 MainThread run_blocking_tasks: creating executor tasks\n",
      "\n",
      "2020-10-30 22:40:41,749:25496 ThreadPoolExecutor-3_0 (task-0): passed args :['taxonomy_cs/test1/data/tg3/tg3_2020-11-01_ford.csv']\n",
      "\n",
      "2020-10-30 22:40:41,750:25496 ThreadPoolExecutor-3_0 (task-0): running\n",
      "\n",
      "[dry_run]: S3 delete from s3://qubole-ford/taxonomy_cs/test1/data/tg3/tg3_2020-11-01_ford.csv \n",
      "2020-10-30 22:40:41,750:25496 ThreadPoolExecutor-3_1 (task-1): passed args :['taxonomy_cs/test1/data/tg3/tg3_2020-11-02_ford.csv']\n",
      "\n",
      "2020-10-30 22:40:41,751:25496 ThreadPoolExecutor-3_2 (task-2): passed args :['taxonomy_cs/test1/data/tg6/tg6_2020-11-01_ford.csv']\n",
      "\n",
      "2020-10-30 22:40:41,751:25496 ThreadPoolExecutor-3_0 (task-0): done\n",
      "\n",
      "2020-10-30 22:40:41,751:25496 ThreadPoolExecutor-3_3 (task-3): passed args :['taxonomy_cs/test1/data/tg6/tg6_2020-11-02_ford.csv']\n",
      "\n",
      "2020-10-30 22:40:41,752:25496 ThreadPoolExecutor-3_1 (task-1): running\n",
      "\n",
      "[dry_run]: S3 delete from s3://qubole-ford/taxonomy_cs/test1/data/tg3/tg3_2020-11-02_ford.csv \n",
      "2020-10-30 22:40:41,752:25496 ThreadPoolExecutor-3_4 (task-4): passed args :['taxonomy_cs/test1/data/tg2/tg2_2020-11-01_ford.csv']\n",
      "\n",
      "2020-10-30 22:40:41,753:25496 ThreadPoolExecutor-3_5 (task-5): passed args :['taxonomy_cs/test1/data/tg2/tg2_2020-11-02_ford.csv']\n",
      "\n",
      "2020-10-30 22:40:41,753:25496 MainThread run_blocking_tasks: waiting for executor tasks\n",
      "\n",
      "2020-10-30 22:40:41,753:25496 ThreadPoolExecutor-3_2 (task-2): running\n",
      "\n",
      "[dry_run]: S3 delete from s3://qubole-ford/taxonomy_cs/test1/data/tg6/tg6_2020-11-01_ford.csv \n",
      "2020-10-30 22:40:41,755:25496 ThreadPoolExecutor-3_3 (task-3): running\n",
      "\n",
      "[dry_run]: S3 delete from s3://qubole-ford/taxonomy_cs/test1/data/tg6/tg6_2020-11-02_ford.csv 2020-10-30 22:40:41,756:25496 ThreadPoolExecutor-3_1 (task-1): done\n",
      "\n",
      "\n",
      "2020-10-30 22:40:41,757:25496 ThreadPoolExecutor-3_4 (task-4): running\n",
      "\n",
      "[dry_run]: S3 delete from s3://qubole-ford/taxonomy_cs/test1/data/tg2/tg2_2020-11-01_ford.csv \n",
      "2020-10-30 22:40:41,758:25496 ThreadPoolExecutor-3_5 (task-5): running\n",
      "\n",
      "[dry_run]: S3 delete from s3://qubole-ford/taxonomy_cs/test1/data/tg2/tg2_2020-11-02_ford.csv 2020-10-30 22:40:41,759:25496 ThreadPoolExecutor-3_2 (task-2): done\n",
      "\n",
      "\n",
      "2020-10-30 22:40:41,760:25496 ThreadPoolExecutor-3_3 (task-3): done\n",
      "\n",
      "2020-10-30 22:40:41,762:25496 ThreadPoolExecutor-3_4 (task-4): done\n",
      "\n",
      "2020-10-30 22:40:41,763:25496 ThreadPoolExecutor-3_5 (task-5): done\n",
      "\n",
      "2020-10-30 22:40:41,766:25496 MainThread run_blocking_tasks: exiting\n",
      "\n",
      "2020-10-30 22:40:41,767:25496 MainThread run_blocking_tasks: starting\n",
      "\n",
      "2020-10-30 22:40:41,768:25496 MainThread run_blocking_tasks: creating executor tasks\n",
      "\n",
      "2020-10-30 22:40:41,769:25496 ThreadPoolExecutor-4_0 (task-0): passed args :['tg6', 'tg6_2020-11-02_ford.csv', 'taxonomy_cs/test1/src/tg6_2020-11-02_ford.csv', 49]\n",
      "\n",
      "2020-10-30 22:40:41,769:25496 ThreadPoolExecutor-4_1 (task-1): passed args :['tg6', 'tg6_2020-11-01_ford.csv', 'taxonomy_cs/test1/src/tg6_2020-11-01_ford.csv', 49]\n",
      "\n",
      "2020-10-30 22:40:41,770:25496 ThreadPoolExecutor-4_2 (task-2): passed args :['tg0', 'tg0_2020-11-02_ford.csv', 'taxonomy_cs/test1/src/tg0_2020-11-02_ford.csv', 27]\n",
      "\n",
      "2020-10-30 22:40:41,770:25496 ThreadPoolExecutor-4_0 (task-0): running\n",
      "\n",
      "[dry_run]: S3 copy from s3://qubole-ford/taxonomy_cs/test1/src/tg6_2020-11-02_ford.csv to s3://qubole-ford/taxonomy_cs/test1/data/tg6/tg6_2020-11-02_ford.csv\n",
      "2020-10-30 22:40:41,770:25496 ThreadPoolExecutor-4_3 (task-3): passed args :['tg4', 'tg4_2020-11-03_ford.csv', 'taxonomy_cs/test1/src/tg4_2020-11-03_ford.csv', 48]\n",
      "\n",
      "2020-10-30 22:40:41,770:25496 ThreadPoolExecutor-4_4 (task-4): passed args :['tg4', 'tg4_2020-11-01_ford.csv', 'taxonomy_cs/test1/src/tg4_2020-11-01_ford.csv', 48]\n",
      "\n",
      "2020-10-30 22:40:41,771:25496 ThreadPoolExecutor-4_1 (task-1): running\n",
      "\n",
      "[dry_run]: S3 copy from s3://qubole-ford/taxonomy_cs/test1/src/tg6_2020-11-01_ford.csv to s3://qubole-ford/taxonomy_cs/test1/data/tg6/tg6_2020-11-01_ford.csv\n",
      "2020-10-30 22:40:41,771:25496 ThreadPoolExecutor-4_5 (task-5): passed args :['tg4', 'tg4_2020-11-02_ford.csv', 'taxonomy_cs/test1/src/tg4_2020-11-02_ford.csv', 48]\n",
      "\n",
      "2020-10-30 22:40:41,772:25496 ThreadPoolExecutor-4_6 (task-6): passed args :['tg2', 'tg2_2020-11-01_ford.csv', 'taxonomy_cs/test1/src/tg2_2020-11-01_ford.csv', 50]\n",
      "\n",
      "2020-10-30 22:40:41,773:25496 ThreadPoolExecutor-4_2 (task-2): running\n",
      "\n",
      "[dry_run]: S3 copy from s3://qubole-ford/taxonomy_cs/test1/src/tg0_2020-11-02_ford.csv to s3://qubole-ford/taxonomy_cs/test1/data/tg0/tg0_2020-11-02_ford.csv\n",
      "2020-10-30 22:40:41,773:25496 ThreadPoolExecutor-4_7 (task-7): passed args :['tg2', 'tg2_2020-11-02_ford.csv', 'taxonomy_cs/test1/src/tg2_2020-11-02_ford.csv', 50]\n",
      "\n",
      "2020-10-30 22:40:41,773:25496 ThreadPoolExecutor-4_8 (task-8): passed args :['tg2', 'tg2_2020-11-03_ford.csv', 'taxonomy_cs/test1/src/tg2_2020-11-03_ford.csv', 50]\n",
      "\n",
      "2020-10-30 22:40:41,774:25496 ThreadPoolExecutor-4_9 (task-9): passed args :['tg7', 'tg7_2020-11-01_ford.csv', 'taxonomy_cs/test1/src/tg7_2020-11-01_ford.csv', 48]\n",
      "\n",
      "2020-10-30 22:40:41,774:25496 MainThread run_blocking_tasks: waiting for executor tasks\n",
      "\n",
      "2020-10-30 22:40:41,775:25496 ThreadPoolExecutor-4_0 (task-0): done\n",
      "\n",
      "2020-10-30 22:40:41,775:25496 ThreadPoolExecutor-4_3 (task-3): running\n",
      "\n",
      "[dry_run]: S3 copy from s3://qubole-ford/taxonomy_cs/test1/src/tg4_2020-11-03_ford.csv to s3://qubole-ford/taxonomy_cs/test1/data/tg4/tg4_2020-11-03_ford.csv\n",
      "2020-10-30 22:40:41,776:25496 ThreadPoolExecutor-4_4 (task-4): running\n",
      "\n",
      "[dry_run]: S3 copy from s3://qubole-ford/taxonomy_cs/test1/src/tg4_2020-11-01_ford.csv to s3://qubole-ford/taxonomy_cs/test1/data/tg4/tg4_2020-11-01_ford.csv\n",
      "2020-10-30 22:40:41,777:25496 ThreadPoolExecutor-4_1 (task-1): done\n",
      "\n",
      "2020-10-30 22:40:41,778:25496 ThreadPoolExecutor-4_5 (task-5): running\n",
      "\n",
      "[dry_run]: S3 copy from s3://qubole-ford/taxonomy_cs/test1/src/tg4_2020-11-02_ford.csv to s3://qubole-ford/taxonomy_cs/test1/data/tg4/tg4_2020-11-02_ford.csv\n",
      "2020-10-30 22:40:41,779:25496 ThreadPoolExecutor-4_6 (task-6): running\n",
      "\n",
      "[dry_run]: S3 copy from s3://qubole-ford/taxonomy_cs/test1/src/tg2_2020-11-01_ford.csv to s3://qubole-ford/taxonomy_cs/test1/data/tg2/tg2_2020-11-01_ford.csv\n",
      "2020-10-30 22:40:41,779:25496 ThreadPoolExecutor-4_2 (task-2): done\n",
      "\n",
      "2020-10-30 22:40:41,780:25496 ThreadPoolExecutor-4_7 (task-7): running\n",
      "\n",
      "[dry_run]: S3 copy from s3://qubole-ford/taxonomy_cs/test1/src/tg2_2020-11-02_ford.csv to s3://qubole-ford/taxonomy_cs/test1/data/tg2/tg2_2020-11-02_ford.csv\n",
      "2020-10-30 22:40:41,781:25496 ThreadPoolExecutor-4_8 (task-8): running\n",
      "\n",
      "[dry_run]: S3 copy from s3://qubole-ford/taxonomy_cs/test1/src/tg2_2020-11-03_ford.csv to s3://qubole-ford/taxonomy_cs/test1/data/tg2/tg2_2020-11-03_ford.csv2020-10-30 22:40:41,782:25496 ThreadPoolExecutor-4_9 (task-9): running\n",
      "\n",
      "\n",
      "[dry_run]: S3 copy from s3://qubole-ford/taxonomy_cs/test1/src/tg7_2020-11-01_ford.csv to s3://qubole-ford/taxonomy_cs/test1/data/tg7/tg7_2020-11-01_ford.csv\n",
      "2020-10-30 22:40:41,783:25496 ThreadPoolExecutor-4_0 (task-10): passed args :['tg7', 'tg7_2020-11-02_ford.csv', 'taxonomy_cs/test1/src/tg7_2020-11-02_ford.csv', 48]\n",
      "\n",
      "2020-10-30 22:40:41,784:25496 ThreadPoolExecutor-4_3 (task-3): done\n",
      "\n",
      "2020-10-30 22:40:41,785:25496 ThreadPoolExecutor-4_4 (task-4): done\n",
      "\n",
      "2020-10-30 22:40:41,785:25496 ThreadPoolExecutor-4_1 (task-11): passed args :['tg5', 'tg5_2020-11-03_ford.csv', 'taxonomy_cs/test1/src/tg5_2020-11-03_ford.csv', 48]\n",
      "\n",
      "2020-10-30 22:40:41,786:25496 ThreadPoolExecutor-4_5 (task-5): done\n",
      "\n",
      "2020-10-30 22:40:41,787:25496 ThreadPoolExecutor-4_6 (task-6): done\n",
      "\n",
      "2020-10-30 22:40:41,788:25496 ThreadPoolExecutor-4_2 (task-12): passed args :['tg5', 'tg5_2020-11-01_ford.csv', 'taxonomy_cs/test1/src/tg5_2020-11-01_ford.csv', 48]\n",
      "\n",
      "2020-10-30 22:40:41,790:25496 ThreadPoolExecutor-4_7 (task-7): done\n",
      "\n",
      "2020-10-30 22:40:41,790:25496 ThreadPoolExecutor-4_8 (task-8): done\n",
      "\n",
      "2020-10-30 22:40:41,791:25496 ThreadPoolExecutor-4_9 (task-9): done\n",
      "\n",
      "2020-10-30 22:40:41,791:25496 ThreadPoolExecutor-4_0 (task-10): running\n",
      "\n",
      "[dry_run]: S3 copy from s3://qubole-ford/taxonomy_cs/test1/src/tg7_2020-11-02_ford.csv to s3://qubole-ford/taxonomy_cs/test1/data/tg7/tg7_2020-11-02_ford.csv\n",
      "2020-10-30 22:40:41,792:25496 ThreadPoolExecutor-4_3 (task-13): passed args :['tg5', 'tg5_2020-11-02_ford.csv', 'taxonomy_cs/test1/src/tg5_2020-11-02_ford.csv', 48]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-30 22:40:41,794:25496 ThreadPoolExecutor-4_4 (task-14): passed args :['tg1', 'tg1_2020-11-01_ford.csv', 'taxonomy_cs/test1/src/tg1_2020-11-01_ford.csv', 48]\n",
      "\n",
      "2020-10-30 22:40:41,794:25496 ThreadPoolExecutor-4_1 (task-11): running\n",
      "\n",
      "[dry_run]: S3 copy from s3://qubole-ford/taxonomy_cs/test1/src/tg5_2020-11-03_ford.csv to s3://qubole-ford/taxonomy_cs/test1/data/tg5/tg5_2020-11-03_ford.csv\n",
      "2020-10-30 22:40:41,795:25496 ThreadPoolExecutor-4_5 (task-15): passed args :['tg1', 'tg1_2020-11-02_ford.csv', 'taxonomy_cs/test1/src/tg1_2020-11-02_ford.csv', 48]\n",
      "\n",
      "2020-10-30 22:40:41,797:25496 ThreadPoolExecutor-4_2 (task-12): running\n",
      "\n",
      "[dry_run]: S3 copy from s3://qubole-ford/taxonomy_cs/test1/src/tg5_2020-11-01_ford.csv to s3://qubole-ford/taxonomy_cs/test1/data/tg5/tg5_2020-11-01_ford.csv\n",
      "2020-10-30 22:40:41,800:25496 ThreadPoolExecutor-4_0 (task-10): done\n",
      "\n",
      "2020-10-30 22:40:41,800:25496 ThreadPoolExecutor-4_3 (task-13): running\n",
      "\n",
      "[dry_run]: S3 copy from s3://qubole-ford/taxonomy_cs/test1/src/tg5_2020-11-02_ford.csv to s3://qubole-ford/taxonomy_cs/test1/data/tg5/tg5_2020-11-02_ford.csv2020-10-30 22:40:41,801:25496 ThreadPoolExecutor-4_4 (task-14): running\n",
      "\n",
      "\n",
      "[dry_run]: S3 copy from s3://qubole-ford/taxonomy_cs/test1/src/tg1_2020-11-01_ford.csv to s3://qubole-ford/taxonomy_cs/test1/data/tg1/tg1_2020-11-01_ford.csv2020-10-30 22:40:41,802:25496 ThreadPoolExecutor-4_1 (task-11): done\n",
      "\n",
      "\n",
      "2020-10-30 22:40:41,803:25496 ThreadPoolExecutor-4_5 (task-15): running\n",
      "\n",
      "[dry_run]: S3 copy from s3://qubole-ford/taxonomy_cs/test1/src/tg1_2020-11-02_ford.csv to s3://qubole-ford/taxonomy_cs/test1/data/tg1/tg1_2020-11-02_ford.csv\n",
      "2020-10-30 22:40:41,804:25496 ThreadPoolExecutor-4_2 (task-12): done\n",
      "\n",
      "2020-10-30 22:40:41,805:25496 ThreadPoolExecutor-4_3 (task-13): done\n",
      "\n",
      "2020-10-30 22:40:41,805:25496 ThreadPoolExecutor-4_4 (task-14): done\n",
      "\n",
      "2020-10-30 22:40:41,808:25496 ThreadPoolExecutor-4_5 (task-15): done\n",
      "\n",
      "2020-10-30 22:40:41,811:25496 MainThread run_blocking_tasks: exiting\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' Extract Info needed to expose configs and show in logs and reports'''\n",
    "\n",
    "invalid_files_set = src_delta['invalid_files_set']\n",
    "invalid_schema_files = src_delta['invalid_schema_files']\n",
    "\n",
    "tg_data = { k for k in tg_data_files_dict.keys()}\n",
    "tg_existing = { k for k in src_delta['existing_tg_files_dict'].keys()}\n",
    "tg_new ={ k for k in src_delta['new_tg_files_dict'].keys()}\n",
    "tg_all = tg_new.union(tg_existing)\n",
    "\n",
    "many_tg4schema_check_gen = (v for k, v in src_delta['schema_tg_dict'].items() if len(v) > 1)\n",
    "many_tg4target_check_gen = (v for k, v in src_delta['target_tg_dict'].items() if len(v) > 1)\n",
    "newTg4schema = {k for k, v in src_delta['new_tg_schema_dict'].items() if len(v) > 1}\n",
    "\n",
    "\n",
    "tg4schema = set()\n",
    "[tg4schema.update(i) for i in many_tg4schema_check_gen]\n",
    "tg4target = set()\n",
    "[tg4target.update(i) for i in many_tg4target_check_gen]\n",
    "\n",
    "\n",
    "invalid_tg_with_dup_schema = (tg4schema.union(newTg4schema)).difference(tg_existing)\n",
    "\n",
    "invalid_tg_with_dup_target = tg4target.difference(tg_existing)\n",
    "\n",
    "invalid_tg_all = invalid_tg_with_dup_schema.union(invalid_tg_with_dup_target)\n",
    "\n",
    "tg_delta = tg_new.difference(invalid_tg_all)\n",
    "\n",
    "tg_delta_create = tg_delta.difference(tg_data)\n",
    "\n",
    "tg_delta_drop_n_create = (tg_delta.intersection(tg_data)).difference(tg_existing)\n",
    "\n",
    "tg_dropped = tg_data.difference(tg_all)\n",
    "\n",
    "tg_dropped_all = tg_dropped.union(tg_delta_drop_n_create)\n",
    "tg_create_all = tg_delta_create.union(tg_delta_drop_n_create)\n",
    "\n",
    "''' File Sync'''\n",
    "files_to_be_dropped_args = [ [f['Key']] for i in  tg_dropped_all for fn, f in tg_data_files_dict.get(i).items()]\n",
    "\n",
    "files_to_be_created = [[i, f['FileName'], f['Key'], f['Size']] for i in  tg_create_all for fn, f in src_delta['new_tg_files_dict'].get(i).items()]\n",
    "files_to_be_copied = [[k, f_dict['FileName'], f_dict['Key'], f_dict['Size']] for k, v in src_delta['existing_tg_files_dict'].items() for f, f_dict in v.items()] #['Key']]\n",
    "file_copy_args = []\n",
    "file_copy_args.extend(files_to_be_created )\n",
    "file_copy_args.extend(files_to_be_copied )\n",
    "\n",
    "collected = NIO.decorated_run_io(task=s3_remove_at_data_loc_task, task_n_args_list=files_to_be_dropped_args, \n",
    "                                 is_kernal_thread=False,)\n",
    "\n",
    "collected = NIO.decorated_run_io(task=s3_copy_into_data_loc_task, task_n_args_list=file_copy_args, \n",
    "                                 is_kernal_thread=False,)\n",
    "\n",
    "\n",
    "\n",
    "''' Expose details to generate configs'''\n",
    "tg_create_all_n_schema = {tg: schema for tg in tg_create_all for schema in src_delta['new_tg_schema_dict'].get(tg)}\n",
    "tg_retain_all_n_schema = {tg: tg_data_schema_dict.get(tg) for tg in tg_existing}\n",
    "#tg_dropped\n",
    "\n",
    "\n",
    "''' Report '''\n",
    "# invalid files Schema delails\n",
    "# To Be\n",
    "\n",
    "# TG level\n",
    "tg_create_n_schema = [(i, src_delta['new_tg_schema_dict'].get(i)) for i in tg_delta_create]\n",
    "tg_drop_create_n_schema = [(tg, tg_data_schema_dict.get(tg), schema_new) for tg in tg_delta_drop_n_create for schema_new in src_delta['new_tg_schema_dict'].get(tg)]\n",
    "tg_drop_n_schema = [(i, tg_data_schema_dict.get(i)) for i in tg_dropped]\n",
    "tg_retain_n_schema = [(i, tg_data_schema_dict.get(i)) for i in tg_existing]\n",
    "\n",
    "# File Level\n",
    "files_to_be_dropped = [ f['Key'] for i in  tg_dropped for fn, f in tg_data_files_dict.get(i).items()]\n",
    "files_to_be_dropped_schema_change = [ f['Key'] for i in  tg_delta_drop_n_create for fn, f in tg_data_files_dict.get(i).items()]\n",
    "files_to_be_created = {f['Key'] :f['Schema'] for i in  tg_delta_create for fn, f in src_delta['new_tg_files_dict'].get(i).items()}\n",
    "files_to_be_created_schema_change = {f['Key'] :f['Schema'] for i in  tg_delta_drop_n_create for fn, f in src_delta['new_tg_files_dict'].get(i).items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tg6': 'key_a6,target_a61',\n",
       " 'tg0': 'key_a0,target_a0',\n",
       " 'tg4': 'key_a4,target_a4',\n",
       " 'tg2': 'key_a21,target_a21'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg_create_all_n_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tg1': 'key_a1,target_a1',\n",
       " 'tg7': 'key_a7,target_a7',\n",
       " 'tg5': 'key_a5,target_a5'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg_retain_all_n_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_util",
   "language": "python",
   "name": "aws_util"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
